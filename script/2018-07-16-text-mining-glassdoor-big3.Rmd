---
layout: post
title: Text Mining Company Reviews (in R)
subtitle: Case of MBB Consulting
bigimg: /img/mckbuilding.jpg
tags: [r-project, glassdoor, webscraping, text-mining, text-analytics, sentiment-analysis]
output: 
  html_document: 
    keep_md: yes
---


```{r Prelim, include=FALSE}
########## P1. PRELIMS ##########
library(tidytext)   #split column into tokens by unnest_token() & get sentiments using bing()
library(tidyverse)  #includes: dplyr, ggplot2, stringr; tidyr
library(rvest)      #scrape
library(purrr)      #iterate scraping by map_df()

library(knitr)      #report generation
options(knitr.table.format = "html")
library(kableExtra) #format tables
library(installr)   #pdf output
library(readr)      #writeLines for wrapping cat()
```

```{r RatingSummary, message=FALSE, warning=FALSE, include=FALSE}
########## P2. RATING SUMMARY TABLE ##########
Rate.Overall <- c("4.7", "4.3", "4.2")
Rate.Culture <- c("4.8", "4.3", "4.3")
Rate.WorkLifeBalance <- c("3.6", "3.1", "2.7")
Rate.SrMgmnt <- c("4.5", "3.9", "3.8")
Rate.Compensation <-c("4.7", "4.4", "4.2")
Rate.CareerOppor <- c("4.7", "4.3", "4.3")

Firm <- c("Bain & Co.", "Boston Consulting Group", "McKinsey & Co.")

ratingSum <- data.frame(Firm, Rate.Overall, Rate.Culture,Rate.SrMgmnt, Rate.WorkLifeBalance, Rate.Compensation, Rate.CareerOppor)
colnames(ratingSum) = c("Firm", "Overall", "Culture", "Sr. Mgmt", "Work-Life Bal.", "Compensation", "Career Opp.")
```

```{r ReviewsFeedp1, message=FALSE, warning=FALSE, include=FALSE}
########## P3 REVIEWS FEED DATAFRAME ########## 
## a. Web scraping

path.source <- ("C:/Users/Rie Guide/Google Drive/NerdyRie/IP - GitHub/Repos/text-mining-glassdoor-big3/source scrape Big3.R")

company <- "Bain-and-Company-Reviews-E3752"
source(path.source, local = TRUE)$value     # calls the source script
df.z$rev.firm <- "Bain"
df.z$rev.id <- as.numeric(rownames(df.z))                       #add ID
df.BAC <- df.z

company <- "Boston-Consulting-Group-Reviews-E3879"
source(path.source, local = TRUE)$value     # calls the source script
df.z$rev.firm <- "BCG"
df.z$rev.id <- as.numeric(rownames(df.z))                       #add ID
df.BCG <- df.z

company <- "McKinsey-and-Company-Reviews-E2893"
source(path.source, local = TRUE)$value     # calls the source script
df.z$rev.firm <- "McKinsey"
df.z$rev.id <- as.numeric(rownames(df.z))                       #add ID
df.MCK <- df.z

# Combine
df <- rbind(df.BAC, df.BCG, df.MCK)
write.csv(df.BAC, "tempdf.BAC.csv", row.names = F)
write.csv(df.BCG, "tempdf.BCG.csv", row.names = F)
write.csv(df.MCK, "tempdf.MCK.csv", row.names = F)

# Check class types and change as needed
sapply(df, class)

cols.char <- c("rev.date", "rev.sum", "rev.title", "rev.pros", "rev.cons", "rev.helpf", "rev.firm")
df[cols.char] <- sapply(df[cols.char],as.character)

df$rev.id <- as.numeric(df$rev.id)
```

```{r ReviewsFeedp2, message=FALSE, warning=FALSE, include=FALSE}
## b. Clean & add fields
df <- subset(df, rev.date!="Featured Review")               #remove any without a date 

df$rev.helpf <- as.numeric(gsub("\\D", "", df$rev.helpf))   #clean Helpf

df$rev.year <- as.numeric(sub(".*, ","", df$rev.date))      #extract Year
df <- subset(df, rev.year!="0")                             #remove any without a date 

df$rev.pos <- sub(".* Employee - ", "", df$rev.title)       #extract Position
df$rev.pos <- sub(" in .*", "", df$rev.pos)

df$rev.loc <- sub(".*\\ in ", "", df$rev.title)             #extract Location
df$rev.loc <- ifelse(df$rev.loc %in% 
                       (grep("Former Employee|Current Employee", df$rev.loc, value = T)), 
                     "Not Given", df$rev.loc)

df$rev.stat <- str_extract(df$rev.title, ".* Employee -")   #extract Status
df$rev.stat <- sub(" Employee -", "", df$rev.stat)

df$rev.prikey <- as.numeric(rownames(df))
```


```{r Pros NGrams, message=FALSE, warning=FALSE, include=FALSE}
########## P4.1 PROS N-GRAMS ##########
## a. TIDY
# Create df text and clean up a bit
tidy.pros <- df[c("rev.id", "rev.pros", "rev.firm")]
tidy.pros$rev.pros <- gsub("Bain|BCG|McKinsey", " ", tidy.pros$rev.pros)

# Tidy words for unigrams
words.pros <- tidy.pros %>% unnest_tokens(word, rev.pros)             #transform text into words
words.pros <- subset(words.pros, grepl('\\D', words.pros$word))       #omit digit words tokens
words.pros <- words.pros %>% anti_join(stop_words, by = "word")       #remove stop words

# Tidy words for bigrams
words2.pros <- tidy.pros
words2.pros$rev.pros <- gsub("\\d", "", words2.pros$rev.pros)         #omit words w/ any digits
words2.pros$rev.pros <- gsub("[[:punct:]]", "", words2.pros$rev.pros)     #& punctuation

words2.pros <- words2.pros %>%                                    #transform text into words
  unnest_tokens(word, rev.pros, token = "ngrams", n = 2) %>% 
  separate(word, c("item1", "item2"), sep = " ") %>% 
  filter(!item1 %in% stop_words$word, !item2 %in% stop_words$word) %>%
  unite(word, item1, item2, sep = " ")

## b. UNIGRAMS
unigram.prosplot <- words.pros %>%
  group_by(rev.firm) %>% 
  count(word) %>% 
  top_n(20) %>% 
  arrange(word) %>% 
  ggplot(aes(fill = rev.firm, x = reorder(word, n), y = n)) + 
  geom_col(show.legend = F) +
  facet_wrap(~rev.firm, ncol = 3)+
  scale_fill_manual(values = c("#cc0000", "#177b57", "#2e4480")) +
  coord_flip() + scale_y_continuous(expand = c(0, 0)) + 
  labs(title = "Pros: Single Words Frequency", x = NULL, y = "Frequency") +
  theme_bw(base_size = 10)

## c. BIGRAMS
bigram.prosplot <- words2.pros %>%
  group_by(rev.firm) %>% 
  count(word) %>% 
  top_n(10) %>% 
  arrange(word) %>% 
  ggplot(aes(fill = rev.firm, x = reorder(word, n), y = n)) + 
  geom_col(show.legend = F) +
  facet_wrap(~rev.firm, ncol = 3)+
  scale_fill_manual(values = c("#cc0000", "#177b57", "#2e4480")) +
  coord_flip() + scale_y_continuous(expand = c(0, 0)) + 
  labs(title = "Pros: Pair Words Frequency", x = NULL, y = "Frequency") +
  theme_bw(base_size = 10)
```


```{r Pros Sen, message=FALSE, warning=FALSE, include=FALSE}
########## P5.2 PROS SENTIMENT ##########

# First, create bing reference table of sentiments for each word
bing <- sentiments %>%
  filter(lexicon == "bing") %>% select(-score)

## a. COMPARISON OF SENTIMENTS

# Categorize sentiment
barcompare.pros <- words.pros %>%         #count sentiments using inner join
  inner_join(get_sentiments("bing")) %>%
  count(rev.firm, word, sentiment, sort = TRUE) %>%
  group_by(sentiment) %>% 
  top_n(20) %>% 
  ungroup() %>% 
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = T) +
  facet_wrap(~rev.firm, scales = "free_y") +
  scale_fill_manual(values = c("#254F73", "#56B1F7")) +
  labs(title = "Pros: Sentiment Single Words Frequency", x = NULL, y = "Frequency") +
  coord_flip() +
  theme_bw(base_size = 10)
```

```{r Cons NGrams, message=FALSE, warning=FALSE, include=FALSE}
########## P6.1 CONS N-GRAMS ##########

## a. TIDY
# Create df text
tidy.cons <- df[c("rev.id", "rev.cons", "rev.firm")]
tidy.cons$rev.cons <- gsub("Bain|BCG|McKinsey", " ", tidy.cons$rev.cons)
tidy.cons$rev.cons <- gsub("life style", "lifestyle", tidy.cons$rev.cons)

# Tidy words for unigrams
words.cons <- tidy.cons %>% unnest_tokens(word, rev.cons)             #transform text into words
words.cons <- subset(words.cons, grepl('\\D', words.cons$word))       #omit digit words tokens
words.cons <- words.cons %>% anti_join(stop_words, by = "word")       #remove stop words

# Tidy words for bigrams
words2.cons <- tidy.cons
words2.cons$rev.cons <- gsub("\\d", "", words2.cons$rev.cons)         #omit words w/ any digits
words2.cons$rev.cons <- gsub("[[:punct:]]", "", words2.cons$rev.cons)     #& punctuation

words2.cons <- words2.cons %>%                                        #transform text into words
  unnest_tokens(word, rev.cons, token = "ngrams", n = 2) %>% 
  separate(word, c("item1", "item2"), sep = " ") %>% 
  filter(!item1 %in% stop_words$word, !item2 %in% stop_words$word) %>%
  unite(word, item1, item2, sep = " ")

## b. UNIGRAMS
unigram.consplot <- words.cons %>%
  group_by(rev.firm) %>% 
  count(word) %>% 
  top_n(20) %>% 
  arrange(word) %>% 
  ggplot(aes(fill = rev.firm, x = reorder(word, n), y = n)) + 
  geom_col(show.legend = F) +
  facet_wrap(~rev.firm, ncol = 3)+
  scale_fill_manual(values = c("#cc0000", "#177b57", "#2e4480")) +
  coord_flip() + scale_y_continuous(expand = c(0, 0)) + 
  labs(title = "Cons: Single Words Frequency", x = NULL, y = "Frequency") +
  theme_bw(base_size = 10)

## c. BIGRAMS
bigram.consplot <- words2.cons %>%
  group_by(rev.firm) %>% 
  count(word) %>% 
  top_n(10) %>% 
  arrange(word) %>% 
  ggplot(aes(fill = rev.firm, x = reorder(word, n), y = n)) + 
  geom_col(show.legend = F) +
  facet_wrap(~rev.firm, ncol = 3)+
  scale_fill_manual(values = c("#cc0000", "#177b57", "#2e4480")) +
  coord_flip() + scale_y_continuous(expand = c(0, 0)) + 
  labs(title = "Cons: Pair Words Frequency", x = NULL, y = "Frequency") +
  theme_bw(base_size = 10)
```

```{r Cons Sen, message=FALSE, warning=FALSE, include=FALSE}
########## P6.2 CONS SENTIMENT ##########

# Use previously created bing reference from pros section, i.e., "bing" table

## a. COMPARISON OF SENTIMENTS
# Categorize sentiment
barcompare.cons <- words.cons %>%         #count sentiments using inner join
  inner_join(get_sentiments("bing")) %>%
  count(rev.firm, word, sentiment, sort = TRUE) %>%
  group_by(sentiment) %>%
  top_n(20) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = T) +
  facet_wrap(~rev.firm, scales = "free_y") +
  scale_fill_manual(values = c("#254F73", "#56B1F7")) +
  labs(title = "Cons: Sentiment Single Words Frequency", x = NULL, y = "Frequency") +
  coord_flip() +
  theme_bw(base_size = 10)
```

```{r Pros & Cons SenScore, message=FALSE, warning=FALSE, include=FALSE}
########## P7 SENTIMENT SCORING ##########

## a. PROS SCORING
senscore.pros <- words.pros %>%  #count sentiments using inner join and calculate score
  inner_join(bing) %>% 
  count(rev.id, sentiment) %>% 
  spread(sentiment, n, fill = 0) %>% 
  mutate(wgtdscore.pros = (positive * 1) + (negative * -1))
senscore.pros <- senscore.pros[c("rev.id", "wgtdscore.pros")]   #keep just 2 columns

df <- left_join(df, senscore.pros)    #add to df

## b. CONS SCORING
senscore.cons <- words.cons %>%  #count sentiments using inner join and calculate score
  inner_join(bing) %>% 
  count(rev.id, sentiment) %>% 
  spread(sentiment, n, fill = 0) %>% 
  mutate(wgtdscore.cons = (positive * -1) + (negative * -1)) %>%    #negate positive words
  mutate_if(is.numeric,coalesce,0)
senscore.cons <- senscore.cons[c("rev.id", "wgtdscore.cons")]       #keep just 2 columns

df <- left_join(df, senscore.cons)    #add to df

## d. NET SCORING (Summary + Pros + Cons)
df[is.na(df)] <- 0  #replace NAs with 0

df <- df %>% 
  mutate(score = wgtdscore.pros + wgtdscore.cons)

senscore.sentxt <- df[c("rev.firm", "rev.id", "rev.year","score")]
colnames(senscore.sentxt)[3]<-"Year"

## e. PLOT & SUMMARY STATS
Q1 <- quantile(df$score, .25)   #+2 hline
Q3 <- quantile(df$score, .75)   #-2 hline

senscore.sentxtplot <- senscore.sentxt %>% 
  ggplot(aes(rev.id, score, fill = Year)) +
  geom_bar(stat = "identity", show.legend = T) +
  facet_wrap(~rev.firm, scales = "free_x", ncol = 1, shrink = T) +
  scale_x_continuous(breaks = seq(0, max(df$rev.id), 250)) +
  scale_y_continuous(breaks = seq(-20, 10, 5), limits=c(-20, 10)) +
  geom_hline(aes(yintercept = Q1)) +
  geom_hline(aes(yintercept = Q3)) +
  theme_bw(base_size = 10) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  labs(title = "", y = "Sentiment Score", x = "by Reviewer ID (sorted by date reviewed)")

# Summary stats
ss.min <- aggregate(score~rev.firm, df, min) %>% rename(Min = score)
ss.qrtl.1 <- aggregate(score~rev.firm, df, quantile, 0.25) %>% rename(Qrtl.1 = score)
ss.med <- aggregate(score~rev.firm, df, median) %>% rename(Median = score)
ss.mean <- aggregate(score~rev.firm, df, mean) %>% rename(Mean = score)
ss.qrtl.3 <- aggregate(score~rev.firm, df, quantile, 0.75) %>% rename(Qrtl.3 = score)
ss.max <- aggregate(score~rev.firm, df, max) %>% rename(Max = score)

# Merge multiple dfs based on rev.firm, polish up a bit
ss <- Reduce(merge, list(ss.min, ss.qrtl.1, ss.med, ss.mean, ss.qrtl.3, ss.max)) 
ss$Mean <- round(ss$Mean, 2) 
colnames(ss)[1]<-"Firm"

# By year
annual.score <- aggregate(score~rev.firm + rev.year, df, mean)
annual.score$score <- round(annual.score$score, digits = 2)
colnames(annual.score) <- c("Firm", "Year", "Score")

senscore.sentxtplot.annual <- annual.score %>% 
  ggplot(aes(Year, Score, color = Firm)) +
  geom_line(stat = "identity", size = 2, show.legend = T) +
  geom_hline(aes(yintercept = 0)) +
  scale_x_continuous(minor_breaks = seq(2008 , 2018, 1), breaks = seq(2008, 2018, 1)) +
  scale_y_continuous(breaks = seq(-1.5, 1.5, .5), limits=c(-1.5, 1.5)) +
  scale_color_manual(values = c("#cc0000", "#177b57", "#2e4480")) +
  theme_bw(base_size = 10) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  labs(title = "", y = "Average Sentiment Score", x = "Year")
```


_This post is about applying basic text mining tasks to Glassdoor company reviews to find out what employees write the most about to describe their workplace experiences, and whether they tend to be expressed in a more negative, positive or neutral way. Final results are shown as visuals, both tables and graphs._

=======

Ever wondered what it's like to work for a specific company? If so, you've probably looked into [Glassdoor]( https://www.glassdoor.com). The site contains user-generated content on which people share feedback about company-specific compensation, interview experiences, and post anonymous reviews that evaluate the workplace. Its features include star ratings (on a 5-point scale), where employees award the company stars on a mix of factors such as workplace culture, work/life balance, and senior management. 

The star ratings are enough for some people to get an idea of whether the prospective company has the right environment for them, but for others, it doesn't tell the story about sentiments towards the workplace. Sentiments reflect people's attitudes and opinions based on what they have to say - whether they are positive, negative, or neutral - and can provide a proxy for employee satisfaction. 

It makes sense to want to work at a place where employee satisfaction is high. The more satisfied employees are, the better the attitudes are about their work, and the better their performance will be. This makes a workplace attractive. The reviews section of Glassdoor is a good resource to gauge this, but involves sifting through pages and pages of reviews - some decidedly misleading and exaggerated, others insightful and useful - and it can be a time-consuming endeavor. 

**An alternative is to streamline this task and get a high-level overview shown primarily as tables and charts.** One way to do this is through text mining. The idea is to apply web scraping to the written reviews about a company posted on Glassdoor to create a database of text. After obtaining this data, it can be applied to text analytics and [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis).

We'll use the "Big Three" as an example in this post. That's **McKinsey & Co.**, **The Boston Consulting Company** and **Bain & Co.** - widely known as "MBB" - and they're the world's largest consulting firms by revenue. 

A little bit about MBB: they all focus on strategy consulting at board level and as leaders in their industry, they excel at what they do. The world's most ambitious and brightest minds in business are attracted to these consultancies. They invest heavily in their people who undergo rigorous core strategy training and engage with Fortune 500 clients. They're known for providing ongoing opportunities and support for professional advancement even after leaving the firm (i.e., exit opportunities). However, along with these benefits comes the downsides of long hours and travel requirements that tend to upend life outside of work. 

Having never worked at a Big Three, my observations about what it's like to work there are purely subjective. So with that said, let's check out the results.

**PART 1: REVIEWER PROFILE**

First, let's get an overview of the reviewers' profile in terms of the years that the reviews were posted, as well as the office locations of the MBB firms under review, and the job titles to identify their positions.

The use of peer review sites have grown to a point where today, many consider them to be a generally reliable source of feedback. The growth of Glassdoor is evident here, with MBB employee review contributions growing significantly since the site was created in 2008. To date, nearly 6,500 total reviews have been posted among the three firms.

(Keep in mind that since they all have a different number of reviews, the amount of text we'll be looking at later will be smaller for BCG and larger for McKinsey and Bain.)

```{r, echo=FALSE, message=FALSE, warning=FALSE}
tbl.year <- df %>% 
  group_by(Firm = rev.firm, Year = rev.year) %>%
  summarize(Freq =n()) %>% 
  mutate(Percent = round((Freq/sum(Freq)*100), digits=1)) 

kable(tbl.year[1:33, 2:4], 
      caption = "Number of Reviews by Year") %>%
  kable_styling(bootstrap_options = c("hover", "striped", "condensed"), font_size = 10, full_width = F) %>% 
  column_spec(1, width = "3cm") %>% column_spec(2, width = "2cm") %>% column_spec(3, width = "2cm") %>% 
  group_rows("Bain & Co. - Total Reviews: 2,093", 1, 11) %>%
  group_rows("Boston Consulting Group - Total Reviews: 1,687", 12, 22) %>%
  group_rows("McKinsey & Co. - Total Reviews: 2,709", 23, 33)
```

The locations of reviewers were not given in many instances, but from what is known, offices in New York City, Boston and Chicago are largely represented. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
tbl.loc <- df %>% 
  group_by(Firm = rev.firm, Location = rev.loc) %>%
  summarize(Freq =n()) %>% 
  mutate(Percent = round((Freq/sum(Freq)*100), digits=1)) %>% 
  arrange(Firm, -Percent) %>% 
  top_n(n=5)

kable(tbl.loc[1:16, 2:4], 
      caption = "Top 5 Number of Reviews by Location") %>%
  kable_styling(bootstrap_options = c("hover", "striped", "condensed"), font_size = 10, full_width = F) %>% 
  column_spec(1, width = "5cm") %>% column_spec(2, width = "2cm") %>% column_spec(3, width = "2cm") %>% 
  group_rows("Bain & Co.", 1, 5) %>%
  group_rows("Boston Consulting Group", 6, 11) %>%
  group_rows("McKinsey & Co.", 12, 16) %>% 
  footnote(general = "Note: Top 5 based on percent ranking.", general_title = "")
```

A big chunk of position titles were also unknown, but it's likely that they're mostly different variations of the functional role of a consultant. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
tbl.pos <- df %>% 
  group_by(Firm = rev.firm, Position = rev.pos) %>%
  summarize(Freq =n()) %>% 
  mutate(Percent = round((Freq/sum(Freq)*100), digits=1)) %>% 
  arrange(Firm, -Percent) %>% 
  top_n(n=5)

kable(tbl.pos[1:15, 2:4], 
      caption = "Top 5 Number of Reviews by Position Title") %>%
  kable_styling(bootstrap_options = c("hover", "striped", "condensed"), font_size = 10, full_width = F) %>% 
  column_spec(1, width = "5cm") %>% column_spec(2, width = "2cm") %>% column_spec(3, width = "2cm") %>% 
  group_rows("Bain & Co.", 1, 5) %>%
  group_rows("Boston Consulting Group", 6, 10) %>%
  group_rows("McKinsey & Co.", 11, 15) %>% 
  footnote(general = "Note: Top 5 based on percent ranking.", general_title = "")
```


**PART 2: STAR RATINGS SECTION**

Based on the Glassdoor star ratings, how do MBB employees rate the companies they work for? Pretty high actually. "Overall" ratings between 4 and 5 reflect a workplace where employees are considered "very satisfied." As a baseline comparison, the average is 3.4 where employees say satisfaction is just "OK" (based on the 700,000 employers reviewed on Glassdoor).

```{r, echo=FALSE, message=FALSE, warning=FALSE}
ratingSum %>%
  select("Firm", "Culture", "Sr. Mgmt", "Work-Life Bal.", "Compensation", "Career Opp.", "Overall") %>% 
  kable(caption = "Star Ratings", align = "c") %>%
  kable_styling(c("striped", "hover", "condensed"), position = "center", font_size = 10, full_width = T) %>% 
  column_spec(1, color = "black", bold = T) %>% column_spec(7, bold = T)
```

For Bain employees, satisfaction was highest in all factors when compared to others, especially when it comes to the approval of its senior leadership. McKinsey consistently received relatively lower satisfaction marks, and more so for the work-life balance factor. Ratings for BCG were split down the middle between the two others, but shared more similarities with McKinsey employees.


**PART 3: COMPANY REVIEWS SECTION**

Here's where the text mining was applied. The company reviews section of Glassdoor shows what employees have to say about the workplace. A review is divided into separate topics about the pros and cons. The _pros_ are the advantages and includes comments around what an employee liked or thought worked well in the company. Conversely, the _cons_ are the disadvantages and reflect what employees disliked or thought needed improvement. Requiring user feedback on both topics helped to make reviews more balanced.

**Pros**  
Focusing on just the pros for now, what words are employees using the most to describe their opinions and experiences? The charts below gives us a breakdown of the top words, both singular and pairs (i.e., two words that are used consecutively). For example, "consulting" is a single word, and "consulting firm" are word pairs. 

Bain employees describe something as being "fun" much more than McKinsey or BCG employees, with that word making it as one of the top ten used the most. Then there's "people," "culture," and "learning" in which all are used frequently across the firms. But _what about_ these single words? Unless used together with additional words to provide more distinct meanings, the pros of the workplace remain very vague.

```{r 1unigram.prosplot, echo=FALSE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE}
unigram.prosplot
```

Looking at the word pairs below sheds more light about what are considered the greatest aspects about working at a Big Three: working with "smart people", the opportunities for "professional development," and the "steep learning" curves. 
These reflect the importance of knowledge within consultancy. As for the "culture," Bain employees refer to it as being a "supportive" one. BCG and McKinsey employees have less consensus about the varying words to describe their workplace culture and are not included as among the top pair words.

```{r, 2bigram.prosplot, echo=FALSE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE}
bigram.prosplot
```

Some of these words we've looked at so far are neutral, such as "people," "career," and "team." We can limit them to those categorized as being either positive (e.g., "fun" and "smart") or negative (e.g., "hard" and "uncertain") in sentiment.

```{r 3barcompare.pros, echo=FALSE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE}
barcompare.pros
```

BCG and McKinsey workers are more similar in their use of sentiment expressions, describing their experiences as mostly being "smart" and "amazing" and probably receiving good "benefits" packages. As for workers at Bain, there's more focus on a "fun" and "supportive" environment. Even the negative words used in the context of the pros like "challenging", "hard" and "steep" indicates that they enjoy a demanding environment that tests their abilities. Do you interpret it this way as well? 

**Cons**  
Let's move on to the cons section, where we'll examine the same visuals as above. First, the common single words.

```{r 4unigram.consplot, echo=FALSE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE}
unigram.consplot
```

All three firms reference the "hours" as being the most discussed downside of their workplaces, relatively more at Bain since its frequency is double that of the next word. There's the word "life." Intuitively it makes sense that it's used together with another frequent word, "balance," since after all, context is key and we're talking about the cons. For consultants, "travel" is thought of negatively, possibly because they have to do it so much which is known to be common in this industry. Also, "client" made it on the list, likely referencing the difficulties of meeting the very high demands of clients that is also common in this industry. 

The word pairs below provides some clarification, where indeed some variation of maintaining a good work-life balance is difficult given the hours and travel requirements. 

```{r 5bigram.consplot, echo=FALSE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE}
bigram.consplot
```

For sentiments, "hard", "difficult," and "tough" are synonymous with each other (where "tough" should be considered a negative). Taken together with what we know previously about work-life balance, it's very likely they're describing the challenges of maintaining a normal lifestyle.

```{r 6barcompare.cons, echo=FALSE, fig.height=5, fig.width=7, message=FALSE, warning=FALSE}
barcompare.cons
```

**Sentiment Scoring of Pros & Cons**  
In this section, let's consider whether the written reviews as a whole tend to be expressed in a more negative, positive, or neutral light. One way to determine this is by computing a sentiment score for both the pros and cons taken together.

* For the **pros** text portions of the reviews: Positive words were given +1 point and negative words were given -1 point.

* For the **cons** portion: negative words were assigned -1, however positive words were too. This is because using a positive word to say something negative by negating is significantly more common (e.g., "It's not good" rather than "It's bad").

A net score for each review was derived by summing the +1 and -1 points. It is measured on a polar scale, with a negative value (less than zero) representing a more negative sentiment, and positive value (greater than zero) representing a more positive sentiment. Below shows the distribution of the reviewers' scores.

```{r 7hist, echo=FALSE, message=FALSE, warning=FALSE}
hist <- senscore.sentxt %>% 
  group_by(Firm = rev.firm) %>% 
  ggplot(aes(score)) +
  geom_histogram(breaks=seq(-30, 20, by = 2), 
                 col="#193652", 
                 aes(fill=..count..)) +
  scale_fill_gradient("Count", low="#254F73", high="#56B1F7") +
  facet_wrap(~rev.firm) + 
  labs(title = "Distribution of Sentiment Scores", x = "Score", y = "Frequency") +
  theme_bw(base_size = 10)
hist
```

The variability of sentiment scores shows that reviewers at MBB firms tend be quite neutral in the way they express their experiences. With such a high share of neutrally scored content, which I'll simply interpret as being between -2 and +2, it's likely that most reviewers are making general statements or statements that carry little sentiment, reflecting a lack of emotionally charged opinions.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
kable(ss, 
      caption = "Variability of Sentiment Scores") %>%
  kable_styling(bootstrap_options = c("hover", "striped", "condensed"), 
                font_size = 10, 
                full_width = F) %>% 
  column_spec(1, bold = T)
```

To put this a bit more into perspective, I consider neutral (i.e., for scores be near zero with little variability) to be pretty good in terms of reflecting satisfaction at the workplace. I've applied this sentiment analysis system to various other companies' reviews and score results tended to skew towards a negative polarity with high variability. A tendency for scores to be on a negative spectrum would actually be expected as normal for most employers given what we know about the prevalence of negativity bias common in review platforms (e.g., people are more motivated to write a review when they have a complaint, more words are used to describe negative experiences versus positive ones, etc.).

Lastly, the panel charts below show how the scores have changed over time at each of the three firms. A score for each review is represented by a single blue-shaded bar. It begins with the first review in 2008 and ends with the last review posted to date. Note that each chart is on a free-scale for Reviewer ID (on the x-axis) and each firm has a different number of total reviews; this makes it easier to see patterns within each individual chart however they are harder to compare across charts.

```{r 8senscore.sentxtplot, echo=FALSE, fig.height=12, fig.width=8, message=FALSE, warning=FALSE}
senscore.sentxtplot
```

Again, for our purposes, a review is considered neutral if the score falls between -2 and +2. Notice any patterns? Indeed we do see that the distribution of sentiment among reviewers are around near 0 and neutral, especially for McKinsey reviewers in the past few years. 

Another way of viewing the scores over time is by the annual averages for the three firms. In the chart below, it may appear that there are fluctuations, but it's actually subtle changes considering they're within a close fit range (-1.5 to +1.5). Also, it wasn't until around 2013/2014 that there were enough reviews on an annual basis to provide a more robust corpus body of text to run text analyses on. We're just past half of this year, so the score is incomplete for 2018. 

```{r 9senscore.sentxtplot.annual, echo=FALSE, message=FALSE, warning=FALSE}
senscore.sentxtplot.annual
```

The stars are considered a reliable measure of satisfaction as is, but text analysis gives us an additional piece of the picture that can help us better understand what it's like to work at a particular employer. Given these considerations, sentiments as a proxy for satisfaction among MBB workers over the past ten years have been overall consistently positive. 

**Final Remarks**  
Of course, I'm trying to make things simple here and nothing is really that simple. When creating a sentiment analysis system, pre-processing the text and validating the methodology are crucial steps that can dramatically affect results. A solid sentiment test gets complex, so while this method doesn't fully capture the true sentiments of these reviews, it's a quick way to obtain general sentiments for my purposes. It's based on a decent sample size, the language is clean, there's consistency in format and content, and the contextual subject matter is understood. Also, it helped significantly that the reviews were already clustered by pros and cons topics to provide perspective. A simple recall test was done, where I ran 20 reviews each of ones I deemed positive, negative, and neutral in advance and the results were sensical. 

Additionally, there are some nuances that could be considered in the real world. For example, offices within the same firms at different locations are likely to have their own unique environments. There were also a few reviews I saw that were not written in the English language and should have been translated. I'm interested in getting the bigger picture, and I kept things simple for practicality. 

So I'll leave you to consider these results and encourage you to look into the many resources online where you can leverage text mining and sentiment analysis methods for yourself, perhaps even exploring the application of machine learning techniques. However, keep in mind the many limitations of applying computational methods when trying to uncover complex social phenomena that occurs in natural human language such as sarcasm, humor, persuasion, and so forth. 

=======

**Learning points**

* Learning process included basic exploration and analysis of text to identify patterns, keywords, and other attributes in the data to extract relevant information and then structure the text to derive insights.  
* Demonstrated web scraping, text analytics, and sentiment analysis on word-level using [tidy data principles]( http://r4ds.had.co.nz/tidy-data.html) and using a binary lexicon to classify sentiment words.  
* Developed completely in R, the code can be found in my [github](https://github.com/mguideng/text-mining-big3-reviews).  
* Packages used: tidytext, tidyverse (includes: dplyr, ggplot2, stringr, tidyr), rvest, purr and kableExtra.  
* Inspired by [this post]( https://juliasilge.com/blog/tidytext-0-1-4/) from Julia Silge, co-creator of the tidytext package.
